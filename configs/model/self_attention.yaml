_target_: boolean_nca_cc.models.CircuitSelfAttention
# Configuration for Self-Attention model

defaults:
  - _base

type: "self_attention"
attention_dim: 256 # 64 # 128
mlp_dim: null # If null, will be set to attention_dim * mlp_dim_multiplier
mlp_dim_multiplier: 2
num_heads: 16 # 4 # 8
num_layers: 4 # 1 # 1
dropout_rate: 0.0
zero_init: false
re_zero_update: true 
  
  # Damage behavior
  # hard: current behavior (remove from attention, clamp logits, zero updates)
  # reversible: keep nodes in attention and residual path; add logit bias to damaged nodes
damage_behavior: "reversible"  # Options: "hard", "reversible"
reversible_bias: -10.0